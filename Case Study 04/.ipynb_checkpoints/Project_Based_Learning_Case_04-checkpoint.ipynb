{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f82cc24efc6283e5a98cadb78fc1a465e44c143",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dimas .f\\anaconda3\\envs\\timeseries\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "da0236e4b36ce514c1fec3fd72f236d1fa259131"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _pywrap_tf2: A dynamic link library (DLL) initialization routine failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SGD\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Timeseries\\Lib\\site-packages\\tensorflow\\__init__.py:42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF2_BEHAVIOR\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Timeseries\\Lib\\site-packages\\tensorflow\\python\\tf2.py:21\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Tools to help with the TensorFlow 2.0 transition.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module is meant for TensorFlow internal implementation, not for users of\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mthe TensorFlow library. For that see tf.compat instead.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_tf2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menable\u001b[39m():\n\u001b[0;32m     26\u001b[0m   \u001b[38;5;66;03m# Enables v2 behaviors.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tf2: A dynamic link library (DLL) initialization routine failed."
     ]
    }
   ],
   "source": [
    "# Importing the libraries, fill the import name libraries below\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#Import keras libraries that you need\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "b288a8e2caf6196daec9cd2bc4ca78fe50345845"
   },
   "outputs": [],
   "source": [
    "# Some functions to help out with this code\n",
    "def plot_predictions(test,predicted):\n",
    "    plt.plot(test, color='red',label='Real AABA Stock Price')\n",
    "    plt.plot(predicted, color='blue',label='Predicted AABA Stock Price')\n",
    "    plt.title('AABA Stock Price Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('AABA Stock Price')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    #fill the function to predict\n",
    "def create_LSTM_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def predict_stock_prices_LSTM(train_data, test_data):\n",
    "    # Assuming train_data and test_data are numpy arrays or pandas dataframes\n",
    "    X_train, y_train = train_data[:, :-1], train_data[:, -1]\n",
    "    X_test, y_test = test_data[:, :-1], test_data[:, -1]\n",
    "\n",
    "    # Reshape data for LSTM input (samples, time steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Create and fit LSTM model\n",
    "    model = create_LSTM_model(input_shape=(X_train.shape[1], 1))\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "    # Make predictions on test data\n",
    "    predicted_prices = model.predict(X_test)\n",
    "\n",
    "    return predicted_prices.flatten()\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have train_data and test_data prepared\n",
    "# train_data and test_data should be numpy arrays or pandas dataframes with the same number of features\n",
    "# Call the predict_stock_prices_LSTM function to get predicted prices\n",
    "# Then pass the test_data and predicted_prices to plot_predictions\n",
    "# plot_predictions(test_data[:, -1], predicted_prices)\n",
    "\n",
    "def rmse_eval(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    print(\"The root mean squared error is {}.\".format(rmse))\n",
    "    return rmse\n",
    "    #fill the function for evaluation model\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have test_data and predicted_prices from your prediction function\n",
    "# rmse = rmse_eval(test_data[:, -1], predicted_prices)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "4cf10cf27420eb383b93b15c0895139ea96c0ed3"
   },
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "dataset = pd.read_csv('AABA_2006-01-01_to_2018-01-01', index_col ='Date', parse_dates = True)) #import dataset based on your directory\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "fb4c9db6d8a5bcf20ffad41747cfa5b6215ba220"
   },
   "outputs": [],
   "source": [
    "# Checking for missing values, choose for data training and set in kind of year\n",
    "#a : until year training \n",
    "#b : year for testing\n",
    "training_set = dataset[:'2016'].iloc[:,1:2].values\n",
    "test_set = dataset['2017':].iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write your insight in EDA here\n",
    "Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf5a9463d58e73852d2b70be9611e8cf1f4166fd"
   },
   "outputs": [],
   "source": [
    "#Checking for stock's market company with line plot\n",
    "# We have chosen 'High' attribute for prices. Let's see what it looks like\n",
    "dataset[\"High\"][:'2016'].plot(figsize=(16,4),legend=True)\n",
    "dataset[\"High\"]['2017':].plot(figsize=(16,4),legend=True)\n",
    "plt.legend(['Training set (Before 2017)','Test set (2017 and beyond)'])\n",
    "plt.title('AABA stock price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "bcc9c36165fc07d258bd5ea87874d2da17fa4a4d"
   },
   "outputs": [],
   "source": [
    "# Scaling with minmaxscaller for data train\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking shape of data train\n",
    "training_set_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "fccfb866a2b4c702e0b2742f7c0289512d713d1b"
   },
   "outputs": [],
   "source": [
    "# create data structure to fill how many row for input in your model at data train\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60,2769):\n",
    "    #fill for x_train and y_train here\n",
    " X_train.append(training_set_scaled[i-60:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "#change it into the array\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "637f699d3c4bde4b783de56ed4dd70a1bf59760d"
   },
   "outputs": [],
   "source": [
    "# Reshaping X_train before modelling\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "df20eb7e8062dae0a3aff2182aa440faddd0017d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sequential Modelling\n",
    "model = Sequential()\n",
    "# First LSTM layer with Dropout regularisation\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "model.add(Dropout(0.2))\n",
    "# Second LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "# Third LSTM layer, fill the code below\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "# Fourth LSTM layer, fill the code below\n",
    "model_lstm.add(LSTM(units=50))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "# The output layer\n",
    "model.add(Dense(units=1))\n",
    "# Compiling\n",
    "model.compile(optimizer='rmsprop',loss='mean_squared_error')\n",
    "# Train fitting for the model\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "326fa85615622feb484cc4c848edeec6f7133913"
   },
   "outputs": [],
   "source": [
    "# Prepare for data test similar way for data train\n",
    "dataset_total = pd.concat((dataset[\"High\"][:'2016'],dataset[\"High\"]['2017':]),axis=0\n",
    "# Extract the test data from dataset_total\n",
    "test = dataset_total['2017':]\n",
    "inputs = dataset_total[len(dataset_total)-len(test_set) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "#Transform the inputs\n",
    "inputs  = sc.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking data test shape\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "435b8024814939ac4fbd372baa0cd8cfc78f80bc"
   },
   "outputs": [],
   "source": [
    "# Preparing X_test and predicting the prices of the stock's that you choose\n",
    "X_test = []\n",
    "for i in range(a,b):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "#Predicting stocks price\n",
    "predicted_stock_price = model_lstm.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b774a8e79e53eac89694cafef6b11aa99226b95f"
   },
   "outputs": [],
   "source": [
    "# Visualizing the results for prediction \n",
    "visualize = plot_predictions(test_set,predicted_stock_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6f6db0b6e1f17ac63c06ce49856873d98ba5f00"
   },
   "outputs": [],
   "source": [
    "# Evaluating our model with RMSE function above\n",
    "rmse_eval(test_set,predicted_stock_price)\n",
    "# Evaluating our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4cf704ab3cd091f63b7b9a1b9224a49f0913171"
   },
   "source": [
    "### Write your Insight and advice here :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
